{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e1fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Target: /home/student/sebastian_ma/Learning-to-Look-Closer/data/nnUNet_raw/Dataset601_WMH\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- GLOBAL CONFIGURATION ---\n",
    "DATASET_NAME = \"Dataset601_WMH\"  # Must follow 'DatasetXXX_Name' format\n",
    "SOURCE_DIR = 'data/WMH'\n",
    "OUTPUT_DIR = os.getenv('nnUNet_raw', \"data/nnUNet_raw\")\n",
    "\n",
    "# Define Paths\n",
    "target_base = Path(OUTPUT_DIR) / DATASET_NAME\n",
    "imagesTr = target_base / \"imagesTr\"\n",
    "labelsTr = target_base / \"labelsTr\"\n",
    "imagesTs = target_base / \"imagesTs\"\n",
    "\n",
    "# Create directories\n",
    "for p in [imagesTr, labelsTr, imagesTs]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Setup complete. Target: {target_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69ae45c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting WMH Dataset Audit: data/WMH ---\n",
      "\n",
      "Audit Finished.\n",
      "Total Cases: 60\n",
      "Clean Cases: 60\n",
      "Cases with Issues: 0\n",
      "\n",
      "All WMH cases passed geometry and modality checks!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CHECK_REGISTRATION = True\n",
    "\n",
    "REQ_MODALITIES = [\"pre/FLAIR.nii.gz\", \"pre/T1.nii.gz\"]\n",
    "REQ_LABEL = \"wmh.nii.gz\"\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"--- Starting WMH Dataset Audit: {SOURCE_DIR} ---\")\n",
    "\n",
    "# The WMH structure is: Institute/Scanner/CaseID/\n",
    "# We need to walk through the first two levels to get to CaseID\n",
    "for inst_dir in Path(f'{SOURCE_DIR}/train').iterdir():\n",
    "    if not inst_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for case_dir in inst_dir.iterdir():\n",
    "        if not case_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        case_id = case_dir.name\n",
    "        report = {\"case_id\": case_id, \"missing\": [], \"issue\": \"None\"}\n",
    "\n",
    "        # 1. Check for Missing Files\n",
    "        for req in REQ_MODALITIES:\n",
    "            if not (case_dir / req).exists():\n",
    "                report[\"missing\"].append(req)\n",
    "\n",
    "        if not (case_dir / REQ_LABEL).exists():\n",
    "            report[\"missing\"].append(REQ_LABEL)\n",
    "\n",
    "        # 2. Geometry & Registration Check\n",
    "        if CHECK_REGISTRATION and not report[\"missing\"]:\n",
    "            try:\n",
    "                # Reference: FLAIR (Manual standard is defined on FLAIR space)\n",
    "                ref_path = case_dir / REQ_MODALITIES[0]\n",
    "                ref_img = nib.load(str(ref_path))\n",
    "                ref_affine = ref_img.affine\n",
    "                ref_shape = ref_img.shape\n",
    "\n",
    "                # Check T1 against FLAIR\n",
    "                t1_img = nib.load(str(case_dir / REQ_MODALITIES[1]))\n",
    "                if not np.array_equal(t1_img.shape, ref_shape):\n",
    "                    report[\"issue\"] = \"Shape Mismatch (T1 vs FLAIR)\"\n",
    "                elif not np.allclose(t1_img.affine, ref_affine, atol=1e-3):\n",
    "                    report[\"issue\"] = \"Registration Drift (T1 vs FLAIR)\"\n",
    "\n",
    "                # Check Label against FLAIR\n",
    "                label_img = nib.load(str(case_dir / REQ_LABEL))\n",
    "                if not np.array_equal(label_img.shape, ref_shape):\n",
    "                    report[\"issue\"] = \"Shape Mismatch (Label vs FLAIR)\"\n",
    "                elif not np.allclose(label_img.affine, ref_affine, atol=1e-3):\n",
    "                    report[\"issue\"] = \"Registration Drift (Label vs FLAIR)\"\n",
    "\n",
    "            except Exception as e:\n",
    "                report[\"issue\"] = f\"Error loading NIfTI: {str(e)}\"\n",
    "\n",
    "        results.append(report)\n",
    "\n",
    "# --- Summary Report ---\n",
    "df_audit = pd.DataFrame(results)\n",
    "issues_df = df_audit[(df_audit['missing'].str.len() > 0)\n",
    "                     | (df_audit['issue'] != \"None\")]\n",
    "\n",
    "print(f\"\\nAudit Finished.\")\n",
    "print(f\"Total Cases: {len(df_audit)}\")\n",
    "print(f\"Clean Cases: {len(df_audit) - len(issues_df)}\")\n",
    "print(f\"Cases with Issues: {len(issues_df)}\")\n",
    "\n",
    "if not issues_df.empty:\n",
    "    print(\"\\n--- Summary of Pitfalls Found ---\")\n",
    "    print(issues_df.to_string())\n",
    "else:\n",
    "    print(\"\\nAll WMH cases passed geometry and modality checks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2bc085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. 60 cases processed.\n"
     ]
    }
   ],
   "source": [
    "n_cases = 0\n",
    "\n",
    "def clean_wmh_labels(label_path, output_path):\n",
    "    # Load the manual reference standard (wmh.nii.gz)\n",
    "    img = nib.load(label_path)\n",
    "    data = img.get_fdata()\n",
    "\n",
    "    # Reassign label 2 (Other pathology) to 0 (Background)\n",
    "    # Label 1 (WMH) remains untouched\n",
    "    data[data == 2] = 0\n",
    "\n",
    "    # Save the cleaned label as a new NIfTI file\n",
    "    cleaned_img = nib.Nifti1Image(\n",
    "        data.astype(np.uint8), img.affine, img.header)\n",
    "    nib.save(cleaned_img, output_path)\n",
    "    \n",
    "    \n",
    "for inst_dir in Path(f'{SOURCE_DIR}/train').iterdir():\n",
    "    if not inst_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for case_dir in inst_dir.iterdir():\n",
    "        if not case_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        case_id = case_dir.name\n",
    "\n",
    "        # Use pre-processed images: T1 aligned to FLAIR and FLAIR itself\n",
    "        flair_src = f\"{case_dir}/pre/FLAIR.nii.gz\"\n",
    "        t1_src = f\"{case_dir}/pre/T1.nii.gz\"\n",
    "        label_src = f\"{case_dir}/wmh.nii.gz\"\n",
    "\n",
    "        if os.path.exists(flair_src) and os.path.exists(label_src):\n",
    "            formatted_id = f\"WMH_{case_id}\"\n",
    "\n",
    "            # Copy Images with nnUNet naming convention (Case_Modality.nii.gz)\n",
    "            shutil.copy(flair_src, os.path.join(\n",
    "                imagesTr, f\"{formatted_id}_0000.nii.gz\"))\n",
    "            shutil.copy(t1_src, os.path.join(\n",
    "                imagesTr, f\"{formatted_id}_0001.nii.gz\"))\n",
    "\n",
    "            # Copy Labels\n",
    "            clean_wmh_labels(label_src, f\"{labelsTr}/{formatted_id}.nii.gz\")\n",
    "        n_cases += 1\n",
    "\n",
    "\n",
    "# --- Generate dataset.json ---\n",
    "dataset_json = {\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"FLAIR\",\n",
    "        \"1\": \"T1\"\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"background\": 0,\n",
    "        \"WMH\": 1,\n",
    "    },\n",
    "    \"numTraining\": n_cases,\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "\n",
    "with open(os.path.join(target_base, \"dataset.json\"), 'w') as f:\n",
    "    json.dump(dataset_json, f, indent=4)\n",
    "\n",
    "print(f\"Conversion complete. {n_cases} cases processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c827ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for Dataset601_WMH:\n",
      "Training images: 120\n",
      "Training labels: 120\n",
      "Test images:     0\n",
      "/home/student/sebastian_ma/Learning-to-Look-Closer/data/nnUNet_raw/Dataset601_WMH:\n",
      "dataset.json\n",
      "imagesTr\n",
      "imagesTs\n",
      "labelsTr\n",
      "\n",
      "/home/student/sebastian_ma/Learning-to-Look-Closer/data/nnUNet_raw/Dataset601_WMH/imagesTr:\n",
      "WMH_000_0000.nii.gz\n",
      "WMH_000_0001.nii.gz\n",
      "WMH_001_0000.nii.gz\n",
      "WMH_001_0001.nii.gz\n",
      "WMH_002_0000.nii.gz\n",
      "WMH_002_0001.nii.gz\n",
      "WMH_003_0000.nii.gz\n",
      "WMH_003_0001.nii.gz\n",
      "WMH_004_0000.nii.gz\n",
      "WMH_004_0001.nii.gz\n",
      "WMH_005_0000.nii.gz\n",
      "WMH_005_0001.nii.gz\n",
      "WMH_006_0000.nii.gz\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary for {DATASET_NAME}:\")\n",
    "print(f\"Training images: {len(list(imagesTr.glob('*_0000.nii.gz')))}\")\n",
    "print(f\"Training labels: {len(list(labelsTr.glob('*.nii.gz')))}\")\n",
    "print(f\"Test images:     {len(list(imagesTs.glob('*_0000.nii.gz')))}\")\n",
    "\n",
    "# Final directory structure check\n",
    "!ls -R {target_base} | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d67402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Dataset Audit: data/brainmetshare-3 ---\n",
      "\n",
      "Audit Finished.\n",
      "Total Cases: 156\n",
      "Clean Cases: 156\n",
      "Cases with Issues: 0\n",
      "\n",
      "All cases passed geometry and modality checks!\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
